{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import ruamel.yaml as yaml\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from models.model_retrieval import ALBEF\n",
    "from models.vit import interpolate_pos_embed\n",
    "from models.tokenization_bert import BertTokenizer\n",
    "\n",
    "import utils\n",
    "from dataset import create_dataset, create_sampler, create_loader\n",
    "from scheduler import create_scheduler\n",
    "from optim import create_optimizer\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from Retrieval import itm_eval,evaluation\n",
    "def img_show(img):    \n",
    "    img = torch.permute(img,dims=(1,2,0)).detach().numpy()\n",
    "    img = (img- np.min(img)) / (np.max(img) - np.min(img))\n",
    "    #img = img[:,:,::-1]\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    output_dir = './output/Retrieval_coco_romixgen_mixup_textconcat_ratio05_4m_fix2/'\n",
    "    checkpoint = './output/Retrieval_coco_romixgen_mixup_textconcat_ratio05_4m_fix2/checkpoint_2.pth'\n",
    "    text_encoder = 'bert-base-uncased'\n",
    "    device = 'cuda:3'\n",
    "    seed = 42 \n",
    "    world_size = 1 \n",
    "    \n",
    "    \n",
    "#### main ####\n",
    "config = yaml.load(open(os.path.join(args.output_dir,'config.yaml')),Loader=yaml.Loader)\n",
    "\n",
    "\n",
    "seed = args.seed + utils.get_rank()\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "device = args.device\n",
    "\n",
    "#dataset \n",
    "\n",
    "samplers = [None, None, None]\n",
    "train_dataset, val_dataset, test_dataset = create_dataset('re', config)  \n",
    "train_loader, val_loader, test_loader = create_loader([train_dataset, val_dataset, test_dataset],samplers,\n",
    "                                                          batch_size=[config['batch_size_train']]+[config['batch_size_test']]*2,\n",
    "                                                          num_workers=[0,0,0],\n",
    "                                                          is_trains=[True, False, False], \n",
    "                                                          collate_fns=[None,None,None])  \n",
    "\n",
    "# tokenizer \n",
    "tokenizer = BertTokenizer.from_pretrained(args.text_encoder)\n",
    "\n",
    "# Model \n",
    "model = ALBEF(config=config, text_encoder=args.text_encoder, tokenizer=tokenizer)\n",
    "\n",
    "# Model checkpoint \n",
    "checkpoint = torch.load(args.checkpoint, map_location='cpu') \n",
    "state_dict = checkpoint['model']\n",
    "pos_embed_reshaped = interpolate_pos_embed(state_dict['visual_encoder.pos_embed'],model.visual_encoder)         \n",
    "state_dict['visual_encoder.pos_embed'] = pos_embed_reshaped\n",
    "m_pos_embed_reshaped = interpolate_pos_embed(state_dict['visual_encoder_m.pos_embed'],model.visual_encoder_m)   \n",
    "state_dict['visual_encoder_m.pos_embed'] = m_pos_embed_reshaped \n",
    "for key in list(state_dict.keys()):\n",
    "    if 'bert' in key:\n",
    "        encoder_key = key.replace('bert.','')         \n",
    "        state_dict[encoder_key] = state_dict[key] \n",
    "        del state_dict[key]                \n",
    "msg = model.load_state_dict(state_dict,strict=False)  \n",
    "\n",
    "print('load checkpoint from %s'%args.checkpoint)\n",
    "print(msg)  \n",
    "\n",
    "model = model.to(device)\n",
    "model_without_ddp = model\n",
    "#score_val_i2t, score_val_t2i, = evaluation(model_without_ddp, val_loader, tokenizer, device, config)\n",
    "score_test_i2t, score_test_t2i = evaluation(model_without_ddp, test_loader, tokenizer, device, config)\n",
    "\n",
    "#val_result = itm_eval(score_val_i2t, score_val_t2i, val_loader.dataset.txt2img, val_loader.dataset.img2txt)  \n",
    "#print(val_result)\n",
    "test_result = itm_eval(score_test_i2t, score_test_t2i, test_loader.dataset.txt2img, test_loader.dataset.img2txt)    \n",
    "print(test_result)\n",
    "\n",
    "epoch = 4 \n",
    "\n",
    "log_stats = {**{f'val_{k}': v for k, v in val_result.items()},\n",
    "                **{f'test_{k}': v for k, v in test_result.items()},                  \n",
    "            'epoch': epoch,\n",
    "            }\n",
    "with open(os.path.join(args.output_dir, \"log.txt\"),\"w\") as f:\n",
    "    f.write(json.dumps(log_stats) + \"\\n\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast \n",
    "result = [] \n",
    "ratio = [0.01,0.05]\n",
    "method = ['romixgen','vanila']\n",
    "for r in ratio:\n",
    "    for m in method:\n",
    "        line = open(f'./output/Retrieval_coco_small_{r}_{m}/log.txt').readline()\n",
    "        line = ast.literal_eval(line)\n",
    "        result.append({f'{r}_{m}' : line})\n",
    "\n",
    "for i,res in enumerate(result):\n",
    "    if i == 0:\n",
    "        df = pd.DataFrame.from_dict(res,orient='index')\n",
    "    else:\n",
    "        df = pd.concat([df,pd.DataFrame.from_dict(res,orient='index')])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wokring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml \n",
    "from dataset import create_dataset, create_sampler, create_loader\n",
    "config = yaml.load(open('./configs/Retrieval_coco_temp.yaml'),Loader=yaml.Loader)\n",
    "config['romixgen']['text']['romixgen_true'] = True\n",
    "config['romixgen']['text']['method'] = 'txtshuffle'\n",
    " \n",
    "train_dataset, val_dataset, test_dataset = create_dataset('re', config)  \n",
    "samplers = [None, None, None]\n",
    "train_loader, val_loader, test_loader = create_loader([train_dataset, val_dataset, test_dataset],samplers,\n",
    "                                                          batch_size=[config['batch_size_train']]+[config['batch_size_test']]*2,\n",
    "                                                          num_workers=[0,0,0],\n",
    "                                                          is_trains=[True, False, False], \n",
    "                                                          collate_fns=[None,None,None])\n",
    "img_aug = train_dataset.romixgen.img_aug\n",
    "data = next(iter(train_loader))\n",
    "txt = data[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.caption_dataset import re_eval_perturb_dataset\n",
    "import yaml \n",
    "config = yaml.load(open('./configs/Retrieval_coco_temp.yaml'),Loader=yaml.Loader)\n",
    "pertur = None \n",
    "test_dataset = re_eval_perturb_dataset(config['test_file'],config['image_res'], config['image_root'],pertur=pertur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.dataset.romixgen_ratio = 1 \n",
    "train_loader.dataset.romixgen.txt_aug.method = 'mixconcat'\n",
    "a,b,c= next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt1 = [\"I love you so much no way\"]\n",
    "txt2 = [\"No I hate you mad no\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love you No I hate so much no you mad no way'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.romixgen.txt_aug.mix_concat(txt1,txt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I No love I you hate so you much mad no no way'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.romixgen.txt_aug.txt_shuffle(txt1[0],txt2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No I hate you mad no furthermore I love you so much no way'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.romixgen.txt_aug.conjunction_concat(txt1,txt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "replace_word() missing 1 required positional argument: 'obj_cats'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataset\u001b[39m.\u001b[39;49mromixgen\u001b[39m.\u001b[39;49mtxt_aug\u001b[39m.\u001b[39;49mreplace_word(txt1,txt2)\n",
      "\u001b[0;31mTypeError\u001b[0m: replace_word() missing 1 required positional argument: 'obj_cats'"
     ]
    }
   ],
   "source": [
    "train_dataset.romixgen.txt_aug.replace_word(txt1,txt2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
