{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pycocotools.coco import COCO\n",
    "import os\n",
    "import pandas as pd\n",
    "from transformers import MarianMTModel, MarianTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_translation(text, first_model, first_model_tokenizer, second_model, second_model_tokenizer):\n",
    "    \n",
    "    fisrt_formed_text = f\">>fr<< {text}\"\n",
    "    first_translated = first_model.generate(**first_model_tokenizer(fisrt_formed_text, return_tensors=\"pt\", padding=True))\n",
    "    first_translated_text = first_model_tokenizer.decode(first_translated[0], skip_special_tokens=True)\n",
    "    second_formed_text = f\">>en<< {first_translated_text}\"\n",
    "    second_translated = second_model.generate(**second_model_tokenizer(second_formed_text, return_tensors=\"pt\", padding=True))\n",
    "    first_translated_text = second_model_tokenizer.decode(second_translated[0], skip_special_tokens=True)\n",
    "    \n",
    "    return first_translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model_name = 'Helsinki-NLP/opus-mt-en-fr'\n",
    "first_model_tokenizer = MarianTokenizer.from_pretrained(first_model_name)\n",
    "first_model = MarianMTModel.from_pretrained(first_model_name)\n",
    "second_model_name = 'Helsinki-NLP/opus-mt-fr-en'\n",
    "second_model_tokenizer = MarianTokenizer.from_pretrained(second_model_name)\n",
    "second_model = MarianMTModel.from_pretrained(second_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "json_path = \"/root/RobustMixGen_past/data/coco_train.json\"\n",
    "\n",
    "with open(json_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "json_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_augmentation(obj_id, bg_id, json_df):\n",
    "    \"\"\"\n",
    "    obj_id, bg_id 는 모두 'coco_image_id' 형식으로 삽입\n",
    "    5개의 caption 중 첫번째 caption을 가져오는 코드로 우선 작성\n",
    "    obj는 2번째 token 까지, bg는 3번째 token부터 끝까지를 가져오고,\n",
    "    2개의 token을 concat하여 back translation을 진행\n",
    "    이 부분은 추후 변경 필요\n",
    "    \"\"\"\n",
    "    obj_caption = json_df[json_df['image_id'] == obj_id]['caption'].iloc[0]\n",
    "    bg_caption = json_df[json_df['image_id'] == bg_id]['caption'].iloc[0]\n",
    "    \n",
    "    obj_tok = first_model_tokenizer.encode(obj_caption)\n",
    "    bg_tok = first_model_tokenizer.encode(bg_caption)\n",
    "    \n",
    "    concat_token = obj_tok[:2] + bg_tok[2:]\n",
    "    \n",
    "    concat_text = first_model_tokenizer.decode(concat_token, skip_special_tokens=True)\n",
    "    \n",
    "    backtranslated_text = back_translation(concat_text, first_model, first_model_tokenizer, second_model, second_model_tokenizer)\n",
    "    \n",
    "    return backtranslated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py:1313: UserWarning: Using `max_length`'s default (512) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "test_text = text_augmentation(\"coco_522418\", \"coco_475546\", json_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_caption = json_df[json_df['image_id'] == \"coco_522418\"]['caption'].iloc[0]\n",
    "bg_caption = json_df[json_df['image_id'] == \"coco_475546\"]['caption'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('A woman wearing a net on her head cutting a cake. ',\n",
       " 'The patrons enjoy their beverages at the bar.')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_caption , bg_caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A woman takes advantage of her drinks at the bar.'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
